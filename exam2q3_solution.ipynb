{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
        "# Please note that the weight of the grade for the question is relative to its\n",
        "# difficulty. So your Category 1 question will score significantly less than\n",
        "# your Category 5 question.\n",
        "#\n",
        "# WARNING: Do not use lambda layers in your model, they are not supported\n",
        "# on the grading infrastructure. You do not need them to solve the question.\n",
        "#\n",
        "# You must use the Submit and Test button to submit your model\n",
        "# at least once in this category before you finally submit your exam,\n",
        "# otherwise you will score zero for this category.\n",
        "# ======================================================================\n",
        "#\n",
        "# COMPUTER VISION WITH CNNs\n",
        "#\n",
        "# Create and train a classifier to classify images between two classes\n",
        "# (damage and no_damage) using the satellite-images-of-hurricane-damage dataset.\n",
        "# ======================================================================\n",
        "#\n",
        "# ABOUT THE DATASET\n",
        "#\n",
        "# Original Source:\n",
        "# https://ieee-dataport.org/open-access/detecting-damaged-buildings-post-hurricane-satellite-imagery-based-customized\n",
        "# The dataset consists of satellite images from Texas after Hurricane Harvey\n",
        "# divided into two groups (damage and no_damage).\n",
        "# ==============================================================================\n",
        "#\n",
        "# INSTRUCTIONS\n",
        "#\n",
        "# We have already divided the data for training and validation.\n",
        "#\n",
        "# Complete the code in following functions:\n",
        "# 1. preprocess()\n",
        "# 2. solution_model()\n",
        "#\n",
        "# Your code will fail to be graded if the following criteria are not met:\n",
        "# 1. The input shape of your model must be (128,128,3), because the testing\n",
        "#    infrastructure expects inputs according to this specification. You must\n",
        "#    resize all the images in the dataset to this size while pre-processing\n",
        "#    the dataset.\n",
        "# 2. The last layer of your model must be a Dense layer with 1 neuron\n",
        "#    activated by sigmoid since this dataset has 2 classes.\n",
        "#\n",
        "# HINT: Your neural network must have a validation accuracy of approximately\n",
        "# 0.95 or above on the normalized validation dataset for top marks.\n",
        "\n",
        "import urllib\n",
        "import zipfile\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-11-05T18:38:53.915223Z",
          "iopub.execute_input": "2023-11-05T18:38:53.915590Z",
          "iopub.status.idle": "2023-11-05T18:38:53.921764Z",
          "shell.execute_reply.started": "2023-11-05T18:38:53.915561Z",
          "shell.execute_reply": "2023-11-05T18:38:53.919365Z"
        },
        "trusted": true,
        "id": "eucq-xvd09aa"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function downloads and extracts the dataset to the directory that\n",
        "# contains this file.\n",
        "# DO NOT CHANGE THIS CODE\n",
        "# (unless you need to change https to http)\n",
        "def download_and_extract_data():\n",
        "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/certificate/satellitehurricaneimages.zip'\n",
        "    urllib.request.urlretrieve(url, 'satellitehurricaneimages.zip')\n",
        "    with zipfile.ZipFile('satellitehurricaneimages.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall()"
      ],
      "metadata": {
        "id": "4106yIp409ae"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function normalizes the images.\n",
        "# COMPLETE THE CODE IN THIS FUNCTION\n",
        "def preprocess(image, label):\n",
        "  image = image / 255.0 # NORMALIZE YOUR IMAGES HERE (HINT: Rescale by 1/.255)\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "Unu7Cec909ae"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloads and extracts the dataset to the directory that\n",
        "# contains this file.\n",
        "download_and_extract_data()"
      ],
      "metadata": {
        "id": "osDFPvCI09ae"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 128\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# The following code reads the training and validation data from their\n",
        "# respective directories, resizes them into the specified image size\n",
        "# and splits them into batches. You must fill in the image_size\n",
        "# argument for both training and validation data.\n",
        "# HINT: Image size is a tuple\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory='train/',\n",
        "    image_size= (IMG_SIZE, IMG_SIZE)  # MY CODE HERE\n",
        "    , batch_size=BATCH_SIZE)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory='validation/',\n",
        "    image_size= (IMG_SIZE, IMG_SIZE) # MY CODE HERE\n",
        "    , batch_size=BATCH_SIZE)\n",
        "\n",
        "# Normalizes train and validation datasets using the\n",
        "# preprocess() function.\n",
        "# Also makes other calls, as evident from the code, to prepare them for\n",
        "# training.\n",
        "# Do not batch or resize the images in the dataset here since it's already\n",
        "# been done previously.\n",
        "train_ds = train_ds.map(\n",
        "    preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(\n",
        "    tf.data.experimental.AUTOTUNE)\n",
        "val_ds = val_ds.map(\n",
        "    preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_ZjL3G109af",
        "outputId": "7847c8ac-a556-47f5-bfc4-03745a55b776"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to define the model\n",
        "model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(64, (3, 3) , activation = 'relu', input_shape=(128, 128, 3)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3) , activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'), # My LAYERS OF THE MODEL HERE\n",
        "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "])\n",
        "\n",
        "\n",
        "    # If you don't adhere to the instructions in the following comments,\n",
        "    # tests will fail to grade your model:\n",
        "    # The input layer of your model must have an input shape of\n",
        "    # (128,128,3).\n",
        "    # Make sure your last layer has 1 neuron activated by sigmoid.\n",
        "\n",
        "\n",
        "# Code to compile and train the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # MY CODE HERE"
      ],
      "metadata": {
        "id": "m6CKTiU-09af"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, validation_data=val_ds, epochs=10) # MY CODE HERE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6j116hO09af",
        "outputId": "a58a2d17-d8b4-43b8-edf6-f4def08ce31f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 16s 93ms/step - loss: 0.6262 - accuracy: 0.7367 - val_loss: 0.3697 - val_accuracy: 0.8735\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 15s 93ms/step - loss: 0.3373 - accuracy: 0.8736 - val_loss: 0.2512 - val_accuracy: 0.9030\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 14s 91ms/step - loss: 0.2324 - accuracy: 0.9055 - val_loss: 0.2376 - val_accuracy: 0.9070\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 15s 92ms/step - loss: 0.1647 - accuracy: 0.9325 - val_loss: 0.2196 - val_accuracy: 0.9105\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 14s 90ms/step - loss: 0.1382 - accuracy: 0.9454 - val_loss: 0.1991 - val_accuracy: 0.9295\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 15s 91ms/step - loss: 0.1169 - accuracy: 0.9578 - val_loss: 0.1653 - val_accuracy: 0.9315\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 14s 90ms/step - loss: 0.0812 - accuracy: 0.9732 - val_loss: 0.1711 - val_accuracy: 0.9400\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 14s 90ms/step - loss: 0.0672 - accuracy: 0.9784 - val_loss: 0.2765 - val_accuracy: 0.9295\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 15s 91ms/step - loss: 0.0581 - accuracy: 0.9822 - val_loss: 0.2298 - val_accuracy: 0.9345\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 14s 89ms/step - loss: 0.0422 - accuracy: 0.9869 - val_loss: 0.2539 - val_accuracy: 0.9225\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79804c57b100>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ywXViBe355V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}