{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-11-03T09:49:31.062201Z",
          "iopub.status.busy": "2023-11-03T09:49:31.061684Z",
          "iopub.status.idle": "2023-11-03T09:49:31.071543Z",
          "shell.execute_reply": "2023-11-03T09:49:31.069640Z",
          "shell.execute_reply.started": "2023-11-03T09:49:31.062166Z"
        },
        "trusted": true,
        "id": "cjcSA_zEodgj"
      },
      "outputs": [],
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score significantly\n",
        "# less than your Category 5 question.\n",
        "#\n",
        "# Don't use lambda layers in your model.\n",
        "# You do not need them to solve the question.\n",
        "# Lambda layers are not supported by the grading infrastructure.\n",
        "#\n",
        "# You must use the Submit and Test button to submit your model\n",
        "# at least once in this category before you finally submit your exam,\n",
        "# otherwise you will score zero for this category.\n",
        "# ==============================================================================\n",
        "#\n",
        "# BASIC DATASETS QUESTION\n",
        "#\n",
        "# Create a classifier for the German Traffic Signs dataset that classifies\n",
        "# images of traffic signs into 43 classes.\n",
        "# ==============================================================================\n",
        "#\n",
        "# ABOUT THE DATASET\n",
        "#\n",
        "# The dataset contains traffic sign boards from the streets captured into\n",
        "# image files. There are 43 unique classes in total. The images are of shape\n",
        "# (30,30,3).\n",
        "# ==============================================================================\n",
        "#\n",
        "# INSTRUCTIONS\n",
        "#\n",
        "# We have already divided the data for training and validation.\n",
        "#\n",
        "# Complete the code in following functions:\n",
        "# 1. preprocess()\n",
        "# 2. solution_model()\n",
        "#\n",
        "# Your code will fail to be graded if the following criteria are not met:\n",
        "# 1. The input shape of your model must be (30,30,3), because the testing\n",
        "#    infrastructure expects inputs according to this specification.\n",
        "# 2. The last layer of your model must be a Dense layer with 43 neurons\n",
        "#    activated by softmax since this dataset has 43 classes.\n",
        "#\n",
        "# HINT: Your neural network must have a validation accuracy of approximately\n",
        "# 0.95 or above on the normalized validation dataset for top marks.\n",
        "\n",
        "import urllib\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-03T09:49:32.283048Z",
          "iopub.status.busy": "2023-11-03T09:49:32.282584Z",
          "iopub.status.idle": "2023-11-03T09:49:32.292096Z",
          "shell.execute_reply": "2023-11-03T09:49:32.290357Z",
          "shell.execute_reply.started": "2023-11-03T09:49:32.283007Z"
        },
        "trusted": true,
        "id": "we2ccdC9odgm"
      },
      "outputs": [],
      "source": [
        "# This function downloads and extracts the dataset to the directory that\n",
        "# contains this file.\n",
        "# DO NOT CHANGE THIS CODE\n",
        "# (unless you need to change https to http)\n",
        "def download_and_extract_data():\n",
        "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/certificate/germantrafficsigns.zip'\n",
        "    urllib.request.urlretrieve(url, 'germantrafficsigns.zip')\n",
        "    with zipfile.ZipFile('germantrafficsigns.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "\n",
        "# COMPLETE THE CODE IN THIS FUNCTION\n",
        "def preprocess(image, label):\n",
        "    #YOUR CODE HERE\n",
        "    image = image / 255.0 # My code\n",
        "    return image, label\n",
        "\n",
        "\n",
        "# This function loads the data, normalizes and resizes the images, splits it into\n",
        "# train and validation sets, defines the model, compiles it and finally\n",
        "# trains the model. The trained model is returned from this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-03T09:49:33.889627Z",
          "iopub.status.busy": "2023-11-03T09:49:33.889188Z",
          "iopub.status.idle": "2023-11-03T09:49:44.256144Z",
          "shell.execute_reply": "2023-11-03T09:49:44.254700Z",
          "shell.execute_reply.started": "2023-11-03T09:49:33.889594Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de7Vd7yOodgn",
        "outputId": "4acf4d49-9771-4092-b4c0-a994ab5d8b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31367 files belonging to 43 classes.\n",
            "Found 7842 files belonging to 43 classes.\n"
          ]
        }
      ],
      "source": [
        "# Downloads and extracts the dataset to the directory that\n",
        "# contains this file.\n",
        "download_and_extract_data()\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 30\n",
        "\n",
        "# The following code reads the training and validation data from their\n",
        "# respective directories, resizes them into the specified image size\n",
        "# and splits them into batches. You must fill in the image_size\n",
        "# argument for both training and validation data.\n",
        "# HINT: Image size is a tuple\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory='train/',\n",
        "    label_mode='categorical',\n",
        "    image_size=  (IMG_SIZE,IMG_SIZE)\n",
        "    , batch_size = BATCH_SIZE)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory='validation/',\n",
        "    label_mode='categorical',\n",
        "    image_size= (IMG_SIZE,IMG_SIZE)\n",
        "    , batch_size = BATCH_SIZE)\n",
        "\n",
        "# Normalizes train and validation datasets using the\n",
        "# preprocess() function.\n",
        "# Also makes other calls, as evident from the code, to prepare them for\n",
        "# training.\n",
        "# Do not batch or resize the images in the dataset here since it's already\n",
        "# been done previously.\n",
        "\n",
        "train_ds = train_ds.map(\n",
        "    preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(\n",
        "    tf.data.experimental.AUTOTUNE)\n",
        "val_ds = val_ds.map(\n",
        "    preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-03T09:52:08.468782Z",
          "iopub.status.busy": "2023-11-03T09:52:08.468254Z",
          "iopub.status.idle": "2023-11-03T09:52:08.475067Z",
          "shell.execute_reply": "2023-11-03T09:52:08.473777Z",
          "shell.execute_reply.started": "2023-11-03T09:52:08.468743Z"
        },
        "trusted": true,
        "id": "9wq8iLlZodgp"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3) , activation = 'relu', input_shape=(30, 30, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(43, activation='softmax')\n",
        "])\n",
        "\n",
        "# ADD LAYERS OF THE MODEL HERE\n",
        "\n",
        "# If you don't adhere to the instructions in the following comments,\n",
        "# tests will fail to grade your model:\n",
        "# The input layer of your model must have an input shape of\n",
        "# (30,30,3).\n",
        "# Make sure your last layer has 43 neurons activated by softmax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-g6pJ5dEodgp"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # MY CODE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, validation_data=val_ds, epochs=10) # MY CODE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfShGEaxrFEY",
        "outputId": "54218fe2-5812-47d0-db76-c174db732388"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "981/981 [==============================] - 12s 10ms/step - loss: 1.1569 - accuracy: 0.7004 - val_loss: 0.4279 - val_accuracy: 0.8958\n",
            "Epoch 2/10\n",
            "981/981 [==============================] - 7s 7ms/step - loss: 0.2940 - accuracy: 0.9270 - val_loss: 0.2423 - val_accuracy: 0.9404\n",
            "Epoch 3/10\n",
            "981/981 [==============================] - 8s 8ms/step - loss: 0.1726 - accuracy: 0.9584 - val_loss: 0.2469 - val_accuracy: 0.9281\n",
            "Epoch 4/10\n",
            "981/981 [==============================] - 9s 9ms/step - loss: 0.1198 - accuracy: 0.9697 - val_loss: 0.1966 - val_accuracy: 0.9490\n",
            "Epoch 5/10\n",
            "981/981 [==============================] - 9s 9ms/step - loss: 0.0846 - accuracy: 0.9787 - val_loss: 0.2532 - val_accuracy: 0.9348\n",
            "Epoch 6/10\n",
            "981/981 [==============================] - 8s 8ms/step - loss: 0.0683 - accuracy: 0.9819 - val_loss: 0.2180 - val_accuracy: 0.9489\n",
            "Epoch 7/10\n",
            "981/981 [==============================] - 9s 9ms/step - loss: 0.0576 - accuracy: 0.9844 - val_loss: 0.1495 - val_accuracy: 0.9656\n",
            "Epoch 8/10\n",
            "981/981 [==============================] - 7s 7ms/step - loss: 0.0566 - accuracy: 0.9843 - val_loss: 0.1496 - val_accuracy: 0.9666\n",
            "Epoch 9/10\n",
            "981/981 [==============================] - 8s 8ms/step - loss: 0.0452 - accuracy: 0.9877 - val_loss: 0.1288 - val_accuracy: 0.9725\n",
            "Epoch 10/10\n",
            "981/981 [==============================] - 9s 9ms/step - loss: 0.0414 - accuracy: 0.9883 - val_loss: 0.1567 - val_accuracy: 0.9676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7be3dd7132b0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZjXlOP49surc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}